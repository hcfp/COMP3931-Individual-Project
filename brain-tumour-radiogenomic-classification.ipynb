{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport glob\nimport re\nimport sys\n#!pip install git+https://github.com/shijianjian/EfficientNet-PyTorch-3D\n#!pip install torch-summary\nimport cv2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-12T19:50:18.014175Z","iopub.execute_input":"2022-04-12T19:50:18.014537Z","iopub.status.idle":"2022-04-12T19:50:18.968514Z","shell.execute_reply.started":"2022-04-12T19:50:18.014466Z","shell.execute_reply":"2022-04-12T19:50:18.967788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"files = glob.glob('/kaggle/working/*')\nfor f in files:\n    os.remove(f)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:50:18.970126Z","iopub.execute_input":"2022-04-12T19:50:18.970367Z","iopub.status.idle":"2022-04-12T19:50:18.975457Z","shell.execute_reply.started":"2022-04-12T19:50:18.970318Z","shell.execute_reply":"2022-04-12T19:50:18.974808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sys.path.append(\"../input/efficientnetpyttorch3d/EfficientNet-PyTorch-3D\")","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:50:18.976705Z","iopub.execute_input":"2022-04-12T19:50:18.977208Z","iopub.status.idle":"2022-04-12T19:50:18.985177Z","shell.execute_reply.started":"2022-04-12T19:50:18.977172Z","shell.execute_reply":"2022-04-12T19:50:18.984304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Organisers have said these are to be ignored\nexclude = [109, 123, 709]\ntrain_csv = pd.read_csv('/kaggle/input/rsna-miccai-brain-tumor-radiogenomic-classification/train_labels.csv')\ntrain_csv = train_csv[~train_csv.BraTS21ID.isin(exclude)]","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:50:18.988972Z","iopub.execute_input":"2022-04-12T19:50:18.989537Z","iopub.status.idle":"2022-04-12T19:50:19.013186Z","shell.execute_reply.started":"2022-04-12T19:50:18.989501Z","shell.execute_reply":"2022-04-12T19:50:19.012576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(7, 7))\nsns.countplot(data=train_csv, x=\"MGMT_value\")","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:50:19.01432Z","iopub.execute_input":"2022-04-12T19:50:19.014755Z","iopub.status.idle":"2022-04-12T19:50:19.296809Z","shell.execute_reply.started":"2022-04-12T19:50:19.014722Z","shell.execute_reply":"2022-04-12T19:50:19.296166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_IMAGES = 64\nmri_types = ['FLAIR','T1w','T1wCE','T2w']\nSIZE = 240\n\n#https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way\n\ndef load_dicom(path, voi_lut = True, fix_monochrome = True, augment=False):\n    dicom = pydicom.read_file(path)\n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n    # MONOCHROME1 means that the brightness decreases as the value increases\n    # This would lead to inverted images, so we reverse this\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    \n    if augment:\n        rotation_choices = [0, cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_90_COUNTERCLOCKWISE, cv2.ROTATE_180]\n        choice = np.random.randint(0,4)\n        rotation = rotation_choices[choice]\n        data = cv2.rotate(data, rotation)\n    \n    data = cv2.resize(data, (SIZE, SIZE))\n    data = data.astype(np.float64)\n    return data\n\n#loads 64 (SIZE) images from a DICOM file from a single MRI type\ndef load_dicom_3d(brats21id, mri_type, num_imgs=NUM_IMAGES, img_size=SIZE, data_split=\"train\", augment=False):\n    patient_path = os.path.join(f\"/kaggle/input/rsna-miccai-brain-tumor-radiogenomic-classification/{data_split}/\", str(brats21id).zfill(5))\n    x = glob.glob(os.path.join(patient_path, mri_type, \"*\"))\n    paths = sorted(x, key=lambda x: int(x[:-4].split(\"-\")[-1]))\n    middle = len(paths) // 2\n    num_imgs2 = num_imgs // 2\n    bottom = max(0, middle - num_imgs2)\n    top = min(len(paths), middle + num_imgs2)\n    image_3d = np.stack([load_dicom(f, augment=augment) for f in paths[bottom:top]]).transpose()\n    \n    if image_3d.shape[-1] < num_imgs:\n        zero_padding = np.zeros((img_size, img_size, abs(num_imgs - image_3d.shape[-1])))\n        image_3d = np.concatenate((image_3d, zero_padding), axis=-1)\n    \n    #normalise data\n    if np.min(image_3d) < np.max(image_3d):\n        image_3d = image_3d - np.min(image_3d)\n        image_3d = image_3d / np.max(image_3d)\n    return np.expand_dims(image_3d, 0)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:50:19.297954Z","iopub.execute_input":"2022-04-12T19:50:19.299482Z","iopub.status.idle":"2022-04-12T19:50:19.313039Z","shell.execute_reply.started":"2022-04-12T19:50:19.299443Z","shell.execute_reply":"2022-04-12T19:50:19.312282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = load_dicom_3d(9, \"T1wCE\")\nprint(a.shape)\nprint(np.min(a), np.max(a), np.mean(a), np.median(a))","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:50:19.315954Z","iopub.execute_input":"2022-04-12T19:50:19.316163Z","iopub.status.idle":"2022-04-12T19:50:20.548307Z","shell.execute_reply.started":"2022-04-12T19:50:19.316139Z","shell.execute_reply":"2022-04-12T19:50:20.547593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Displays the middle sample of each MRI type for an ID\ndef visualise_sample(brats21id, mgmt_value, types=(\"FLAIR\", \"T1w\", \"T1wCE\", \"T2w\")):\n    plt.figure(figsize=(16, 5)) \n    patient_path = os.path.join(\"/kaggle/input/rsna-miccai-brain-tumor-radiogenomic-classification/train/\", str(brats21id).zfill(5))\n    for i, type in enumerate(types, 1):\n        x = glob.glob(os.path.join(patient_path, type, \"*\"))\n        type_paths = sorted(glob.glob(os.path.join(patient_path, type, \"*\")), key=lambda x: int(x[:-4].split(\"-\")[-1]))\n        data = load_dicom(type_paths[(len(type_paths) // 2)])\n        plt.subplot(1, 4, i)\n        plt.imshow(data, cmap=\"gray\")\n        plt.title(f\"{type}\", fontsize=16)\n\n    plt.suptitle(f\"BraTS21ID: {brats21id}  MGMT_value: {mgmt_value}\", fontsize=16)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:50:20.549465Z","iopub.execute_input":"2022-04-12T19:50:20.549707Z","iopub.status.idle":"2022-04-12T19:50:20.55836Z","shell.execute_reply.started":"2022-04-12T19:50:20.54967Z","shell.execute_reply":"2022-04-12T19:50:20.557176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_sample = train_csv.sample(n=1).values\nrandom_sample_ID = random_sample[0][0]\nrandom_sample_MGMT = random_sample[0][1]\nvisualise_sample(1002, random_sample_MGMT)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:50:20.559981Z","iopub.execute_input":"2022-04-12T19:50:20.560361Z","iopub.status.idle":"2022-04-12T19:50:21.103741Z","shell.execute_reply.started":"2022-04-12T19:50:20.560313Z","shell.execute_reply":"2022-04-12T19:50:21.102002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from efficientnet_pytorch_3d import EfficientNet3D\nfrom efficientnet_pytorch_3d.utils import Conv3dStaticSamePadding\n\nimport torch\nfrom torch import nn\ntorch.set_default_dtype(torch.float64)\n\n#dataset splitting\nfrom sklearn import model_selection as sk_model_selection\n\n#convolutional\nfrom torch.nn import functional as torch_functional","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:50:21.107328Z","iopub.execute_input":"2022-04-12T19:50:21.10761Z","iopub.status.idle":"2022-04-12T19:50:22.623614Z","shell.execute_reply.started":"2022-04-12T19:50:21.107567Z","shell.execute_reply":"2022-04-12T19:50:22.622911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train, valid = sk_model_selection.train_test_split(train_csv, random_state=3220, stratify=train_csv[\"MGMT_value\"],)\nvalid","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:50:22.626906Z","iopub.execute_input":"2022-04-12T19:50:22.627108Z","iopub.status.idle":"2022-04-12T19:50:22.6449Z","shell.execute_reply.started":"2022-04-12T19:50:22.627084Z","shell.execute_reply":"2022-04-12T19:50:22.644159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Dataset(torch.utils.data.Dataset):\n    def __init__(self, image_IDs, targets=None, mri_type=None, split=\"train\", augment=False):\n        self.image_IDs = image_IDs\n        self.targets = targets\n        self.mri_type = mri_type\n        self.split = split\n        self.augment = augment\n        \n    def __len__(self):\n        return len(self.image_IDs)\n    \n    def __getitem__(self, i: int):\n        image_num = self.image_IDs[i]\n        #targets is None when testing\n        if self.targets is not None:\n            data = load_dicom_3d(image_num, self.mri_type, augment=self.augment)\n        else:\n            data = load_dicom_3d(image_num, self.mri_type, data_split=self.split, augment=self.augment)\n        \n        if self.targets is not None:\n            return {\"X\": data, \"y\": torch.tensor(self.targets[i], dtype=torch.float64)}\n        else:\n            return {\"X\": torch.tensor(data, dtype=torch.float64), \"id\": image_num}","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:50:22.646302Z","iopub.execute_input":"2022-04-12T19:50:22.646559Z","iopub.status.idle":"2022-04-12T19:50:22.654914Z","shell.execute_reply.started":"2022-04-12T19:50:22.646526Z","shell.execute_reply":"2022-04-12T19:50:22.653918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        #create a network using efficientnet-b0, that has 2 output classes (MGMT 1/0) and 1 input channel as it is greyscale\n        self.network = EfficientNet3D.from_name(\"efficientnet-b1\", override_params={'num_classes': 2}, in_channels=1)\n        #classifier\n        self.network._fc = nn.Linear(in_features=self.network._fc.in_features, out_features=1, bias=True)\n        \n    def forward(self, x):\n        out = self.network(x)\n        return out","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:50:22.65645Z","iopub.execute_input":"2022-04-12T19:50:22.656954Z","iopub.status.idle":"2022-04-12T19:50:22.66453Z","shell.execute_reply.started":"2022-04-12T19:50:22.656918Z","shell.execute_reply":"2022-04-12T19:50:22.663715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nfrom sklearn.metrics import roc_auc_score\nclass Trainer:\n    def __init__(self, model, device, optimizer, criterion):\n        self.model = model\n        self.device = device\n        self.optimizer = optimizer\n        self.criterion = criterion\n        self.output_model = None\n        self.best_auc = 0\n        \n    def fit(self, epochs, train_loader, valid_loader, path):\n        all_training_losses = []\n        all_valid_losses = []\n        all_auc = []\n        for epoch_n in range(1, epochs + 1):\n            print(f\"Epoch {epoch_n}\")\n            train_loss = self.train_one_epoch(train_loader)\n            valid_loss, auc = self.validate_one_epoch(valid_loader)\n            all_training_losses.append(train_loss)\n            all_valid_losses.append(valid_loss)\n            all_auc.append(auc)\n            print(\"Training loss: \", train_loss)\n            print(\"Validation loss: \", valid_loss)\n            if auc > self.best_auc:\n                self.save_model(path, valid_loss, auc)\n                self.best_auc = auc\n        return all_training_losses, all_valid_losses, all_auc\n                    \n    def train_one_epoch(self, train_dataloader):\n        sum_losses = 0\n        self.model.train()\n        time_start = time.time()\n        for step, batch in enumerate(train_dataloader, 1):\n            print(\"Step: \", step, end='\\r')\n            ids = batch[\"X\"].to(self.device)\n            targets = batch[\"y\"].to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self.model(ids).squeeze(1)\n            \n            loss = self.criterion(outputs, targets)\n            loss.backward()\n\n            sum_losses += loss.detach().item()\n\n            self.optimizer.step()\n        print(time.time() - time_start)\n        average_loss = sum_losses/len(train_dataloader)\n        return average_loss\n\n    \n    def validate_one_epoch(self, valid_dataloader):\n        #set model up for evaluation, disables dropout layers etc.\n        self.model.eval()\n        sum_losses = 0\n        all_outputs = []\n        all_targets = []\n        time_start = time.time()\n        for step, batch in enumerate(valid_dataloader, 1):\n            #deactivate autograd\n            with torch.no_grad():\n                X = batch[\"X\"].to(self.device)\n                targets = batch[\"y\"].to(self.device)\n                \n                outputs = self.model(X).squeeze(1)\n                loss = self.criterion(outputs, targets)\n                \n                sum_losses += loss.detach().item()\n                all_targets.extend(batch[\"y\"].tolist())\n                all_outputs.extend(torch.sigmoid(outputs).tolist())\n                \n        for x in all_targets:\n            if x > 0.5:\n                x = 1\n            else:\n                x = 0\n\n        auc = roc_auc_score(all_targets, all_outputs)\n        print(\"Time: \", time.time() - time_start, \"AUC: \", auc)\n        average_loss = sum_losses/len(valid_dataloader) \n        return average_loss, auc\n\n    def save_model(self, path, loss, auc):\n        self.output_model = f\"{path}_{loss:.2f}_{auc:.2f}.pt\"\n        print(f\"Saving {self.output_model}\")\n        torch.save(self.model.state_dict(), self.output_model)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:50:22.666223Z","iopub.execute_input":"2022-04-12T19:50:22.666512Z","iopub.status.idle":"2022-04-12T19:50:22.686933Z","shell.execute_reply.started":"2022-04-12T19:50:22.666478Z","shell.execute_reply":"2022-04-12T19:50:22.686162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from torchsummary import summary\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndef train_model(train, valid, mri_type):\n    train_dataset = Dataset(\n        train[\"BraTS21ID\"].values,\n        train[\"MGMT_value\"].values,\n        mri_type=mri_type,\n        split=\"train\",\n        augment=True\n    )\n\n    train_loader = torch.utils.data.DataLoader(\n            train_dataset,\n            batch_size=4,\n            shuffle=True,\n            num_workers=2,pin_memory = True\n    )\n    \n    valid_dataset = Dataset(\n        valid[\"BraTS21ID\"].values,\n        valid[\"MGMT_value\"].values,\n        mri_type=mri_type,\n        split=\"train\"\n    )\n\n    valid_loader = torch.utils.data.DataLoader(\n            valid_dataset,\n            batch_size=4,\n            shuffle=True,\n            num_workers=2,pin_memory = True\n    )\n    \n    model = Model()\n    model.to(device)\n    #summary(model, input_size=(1, 256, 256, 64))\n    optimiser = torch.optim.AdamW(model.parameters(), lr=0.001)\n    criterion = torch_functional.binary_cross_entropy_with_logits\n\n    trainer = Trainer(model, device, optimiser, criterion)\n    epochs = 10\n    history = trainer.fit(epochs, train_loader, valid_loader, mri_type)\n    train_losses = history[0]\n    valid_losses = history[1]\n    aucs = history[2]\n    \n    epochs = list(range(1, epochs + 1))\n    \n    fig, axs = plt.subplots(1, 3)\n    fig.suptitle(f\"AUC and loss values over 10 epochs ({mri_type})\")\n    fig.tight_layout()\n    \n    axs[0].plot(epochs, aucs)\n    axs[0].set_title(\"AUC\")\n    axs[1].plot(epochs, train_losses)\n    axs[1].set_title(\"Training loss\")\n    axs[2].plot(epochs, valid_losses)\n    axs[2].set_title(\"Validation loss\")\n    \n    return trainer.output_model","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:50:22.688307Z","iopub.execute_input":"2022-04-12T19:50:22.688618Z","iopub.status.idle":"2022-04-12T19:50:22.753636Z","shell.execute_reply.started":"2022-04-12T19:50:22.688583Z","shell.execute_reply":"2022-04-12T19:50:22.752957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_type = \"FLAIR\"\ntrained_model_path = train_model(train, valid, train_type)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T19:50:22.754938Z","iopub.execute_input":"2022-04-12T19:50:22.755412Z","iopub.status.idle":"2022-04-12T20:25:08.003857Z","shell.execute_reply.started":"2022-04-12T19:50:22.755377Z","shell.execute_reply":"2022-04-12T20:25:08.002425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_prediction(path, valid, mri_type, split):\n    valid.loc[:,\"MRI_Type\"] = mri_type\n    dataset = Dataset(\n        valid.index.values,\n        mri_type=mri_type,\n        split=split\n    )\n    \n    dataloader = torch.utils.data.DataLoader(\n            dataset,\n            batch_size=4,\n            shuffle=False,\n            num_workers=2\n    )\n    \n    model = Model()\n    model.to(device)\n    model.load_state_dict(torch.load(path))\n    model.eval()\n    \n    MGMT_prediction = []\n    patient_ids = []\n    \n    for step, batch in enumerate(dataloader, 1):\n        with torch.no_grad():\n            prediction_sigmoid = torch.sigmoid(model(batch[\"X\"].to(device))).cpu().numpy().squeeze()\n            if prediction_sigmoid.size != 1:\n                MGMT_prediction.extend(prediction_sigmoid.tolist())\n            else:\n                #if batch size happens to be 1\n                MGMT_prediction.append(prediction_sigmoid)\n            patient_ids.extend(batch[\"id\"].numpy().tolist())\n    \n    prediction = pd.DataFrame({\"BraTS21ID\": patient_ids, \"MGMT_value\": MGMT_prediction}) \n    prediction = prediction.set_index(\"BraTS21ID\")\n    return prediction","metadata":{"execution":{"iopub.status.busy":"2022-04-12T20:25:08.008577Z","iopub.execute_input":"2022-04-12T20:25:08.009134Z","iopub.status.idle":"2022-04-12T20:25:08.023848Z","shell.execute_reply.started":"2022-04-12T20:25:08.009089Z","shell.execute_reply":"2022-04-12T20:25:08.022767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid.set_index(\"BraTS21ID\", inplace=True)\nvalid.loc[:, \"MGMT_prediction\"] = 0.0\nprediction = make_prediction(trained_model_path, valid, mri_type=train_type, split=\"train\")\n\nvalid.loc[:,\"MGMT_prediction\"] += prediction.loc[:,\"MGMT_value\"]\n\nauc = roc_auc_score(valid.loc[:, \"MGMT_value\"], valid.loc[:, \"MGMT_prediction\"])\nprint(f\"Validation AUC: {auc}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-12T20:25:08.027424Z","iopub.execute_input":"2022-04-12T20:25:08.028089Z","iopub.status.idle":"2022-04-12T20:25:42.317809Z","shell.execute_reply.started":"2022-04-12T20:25:08.02804Z","shell.execute_reply":"2022-04-12T20:25:42.315993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.displot(valid.loc[:, \"MGMT_prediction\"])","metadata":{"execution":{"iopub.status.busy":"2022-04-12T20:25:42.321405Z","iopub.execute_input":"2022-04-12T20:25:42.323399Z","iopub.status.idle":"2022-04-12T20:25:46.728579Z","shell.execute_reply.started":"2022-04-12T20:25:42.32336Z","shell.execute_reply":"2022-04-12T20:25:46.727816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(f\"/kaggle/input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv\", index_col=\"BraTS21ID\")\n\nsubmission[\"MGMT_value\"] = 0.0\nprediction = make_prediction(trained_model_path, submission, train_type, split=\"test\")\nsubmission[\"MGMT_value\"] += prediction[\"MGMT_value\"]\n\nsubmission[\"MGMT_value\"].to_csv(\"submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-12T20:25:46.731964Z","iopub.execute_input":"2022-04-12T20:25:46.732507Z","iopub.status.idle":"2022-04-12T20:26:26.29068Z","shell.execute_reply.started":"2022-04-12T20:25:46.73247Z","shell.execute_reply":"2022-04-12T20:26:26.28969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.displot(submission[\"MGMT_value\"])","metadata":{"execution":{"iopub.status.busy":"2022-04-12T20:26:26.292197Z","iopub.execute_input":"2022-04-12T20:26:26.292504Z","iopub.status.idle":"2022-04-12T20:26:32.936685Z","shell.execute_reply.started":"2022-04-12T20:26:26.292466Z","shell.execute_reply":"2022-04-12T20:26:32.935844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model()\nmodel.to(device)\nmodel.load_state_dict(torch.load(trained_model_path))","metadata":{"execution":{"iopub.status.busy":"2022-04-12T20:26:32.940441Z","iopub.execute_input":"2022-04-12T20:26:32.940705Z","iopub.status.idle":"2022-04-12T20:26:33.377832Z","shell.execute_reply.started":"2022-04-12T20:26:32.94067Z","shell.execute_reply":"2022-04-12T20:26:33.37542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_3d = load_dicom_3d(1002, train_type)\nimg_3d = torch.tensor(img_3d, dtype=torch.float64).unsqueeze(0).cuda()\n\nconv_weight = model.network._conv_stem.weight.cpu().detach().numpy()\nprint(conv_weight.shape)\nplt.figure(figsize=(10, 10))\nfor i in range(32):\n    plt.subplot(6, 6, i+1)\n    plt.imshow(conv_weight[i, 0, :, :, 2], cmap=\"gray\")","metadata":{"execution":{"iopub.status.busy":"2022-04-12T20:26:33.381934Z","iopub.execute_input":"2022-04-12T20:26:33.382627Z","iopub.status.idle":"2022-04-12T20:26:36.960616Z","shell.execute_reply.started":"2022-04-12T20:26:33.382586Z","shell.execute_reply":"2022-04-12T20:26:36.95988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(img_3d.shape)\nplt.imshow(img_3d[0, 0, :, :, 10].cpu().detach().numpy(), cmap=\"gray\")","metadata":{"execution":{"iopub.status.busy":"2022-04-12T20:26:36.962094Z","iopub.execute_input":"2022-04-12T20:26:36.962628Z","iopub.status.idle":"2022-04-12T20:26:37.200756Z","shell.execute_reply.started":"2022-04-12T20:26:36.962588Z","shell.execute_reply":"2022-04-12T20:26:37.199909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"net_modules = list(model.network.modules())\nconv_layers = []\nlayer_weights = []\nconv_count = 0\n\nfor module in net_modules:\n    if type(module) == Conv3dStaticSamePadding:\n        conv_layers.append(module)\n        layer_weights.append(module.weight)\n        \noutput = []\nnames = []\nimage = img_3d\n\nfor l in conv_layers:\n    names.append(str(l).split(\"(\")[0])\n    image = l(image)\n    output.append(image)\n\nflattened_output = []\nfor o in output:\n    o = o.squeeze(0)\n    grey_scale = torch.sum(o ,0)\n    grey_scale = grey_scale / o.shape[0]\n    flattened_output.append(grey_scale.cpu().detach().numpy())\n    \nfig = plt.figure(figsize=(30, 50))\nfor i in range(len(flattened_output)):\n    sub_plot = fig.add_subplot(9, 9, i+1)\n    image = flattened_output[i]\n    imgplot = plt.imshow(image[:, :, 0])\n    sub_plot.axis(\"off\")\n    sub_plot.set_title(names[i], fontsize=10)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-12T20:26:37.205176Z","iopub.execute_input":"2022-04-12T20:26:37.208799Z","iopub.status.idle":"2022-04-12T20:26:42.35987Z","shell.execute_reply.started":"2022-04-12T20:26:37.20876Z","shell.execute_reply":"2022-04-12T20:26:42.337987Z"},"trusted":true},"execution_count":null,"outputs":[]}]}